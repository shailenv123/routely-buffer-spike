{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Percentiles Analysis\n",
        "\n",
        "This notebook mirrors the functionality in `build_percentiles.py` to compute delay percentiles by route, hour, and day of week.\n",
        "\n",
        "**Note:** Make sure to install dependencies first:\n",
        "```bash\n",
        "pip install -r ../requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Set working directory to project root\n",
        "os.chdir('..')\n",
        "print(f\"Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and concatenate all daily delay files\n",
        "data_files = glob.glob(\"data/raw_delays/delays_*.csv.gz\")\n",
        "print(f\"Found {len(data_files)} data files:\")\n",
        "for file in data_files:\n",
        "    print(f\"  - {file}\")\n",
        "\n",
        "if not data_files:\n",
        "    print(\"No data files found. Run pipeline.py first!\")\n",
        "else:\n",
        "    # Load all files\n",
        "    all_data = []\n",
        "    for file in data_files:\n",
        "        df = pd.read_csv(file, compression=\"gzip\")\n",
        "        all_data.append(df)\n",
        "        print(f\"Loaded {file}: {len(df)} rows\")\n",
        "    \n",
        "    # Combine all data\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    print(f\"\\nCombined dataset: {len(combined_df)} total rows\")\n",
        "    \n",
        "    # Show sample\n",
        "    print(\"\\nSample data:\")\n",
        "    display(combined_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute percentiles (same logic as build_percentiles.py)\n",
        "if 'combined_df' in locals() and not combined_df.empty:\n",
        "    # Derive hour and day of week\n",
        "    combined_df[\"hour\"] = combined_df[\"gbtt_pta\"].str[:2].astype(int)\n",
        "    combined_df[\"date_dt\"] = pd.to_datetime(combined_df[\"date\"])\n",
        "    combined_df[\"dow\"] = combined_df[\"date_dt\"].dt.dayofweek\n",
        "    \n",
        "    # Filter valid data\n",
        "    filtered_df = combined_df.dropna(subset=[\"origin\", \"dest\", \"hour\", \"dow\", \"delay_min\"])\n",
        "    filtered_df = filtered_df[filtered_df[\"delay_min\"] >= 0]\n",
        "    \n",
        "    print(f\"Filtered dataset: {len(filtered_df)} valid rows\")\n",
        "    \n",
        "    # Group by route, hour, and day of week\n",
        "    grouped = filtered_df.groupby([\"origin\", \"dest\", \"hour\", \"dow\"])[\"delay_min\"]\n",
        "    \n",
        "    # Calculate percentiles\n",
        "    percentiles_df = grouped.agg([\n",
        "        (\"p80\", lambda x: x.quantile(0.80)),\n",
        "        (\"p90\", lambda x: x.quantile(0.90)),\n",
        "        (\"p95\", lambda x: x.quantile(0.95)),\n",
        "        (\"obs_count\", \"count\")\n",
        "    ]).reset_index()\n",
        "    \n",
        "    # Flatten column names\n",
        "    percentiles_df.columns = [\"origin\", \"dest\", \"hour\", \"dow\", \"p80\", \"p90\", \"p95\", \"obs_count\"]\n",
        "    \n",
        "    # Sort and round\n",
        "    percentiles_df = percentiles_df.sort_values([\"origin\", \"dest\", \"hour\", \"dow\"]).reset_index(drop=True)\n",
        "    for col in [\"p80\", \"p90\", \"p95\"]:\n",
        "        percentiles_df[col] = percentiles_df[col].round(2)\n",
        "    \n",
        "    print(f\"\\nGenerated {len(percentiles_df)} percentile groups\")\n",
        "    print(f\"Unique routes: {percentiles_df[['origin', 'dest']].drop_duplicates().shape[0]}\")\n",
        "    print(f\"Total observations: {percentiles_df['obs_count'].sum()}\")\n",
        "else:\n",
        "    print(\"No data to process\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write CSV and display sample\n",
        "if 'percentiles_df' in locals() and not percentiles_df.empty:\n",
        "    # Save to CSV\n",
        "    output_path = \"data/route_hour_p80_p90_p95.csv\"\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    percentiles_df.to_csv(output_path, index=False)\n",
        "    \n",
        "    print(f\"âœ… Saved percentiles to {output_path}\")\n",
        "    \n",
        "    # Display sample of results\n",
        "    print(\"\\nSample percentile data:\")\n",
        "    display(percentiles_df.head(10))\n",
        "    \n",
        "    # Summary statistics\n",
        "    print(\"\\nSummary by route:\")\n",
        "    route_summary = percentiles_df.groupby(['origin', 'dest']).agg({\n",
        "        'obs_count': 'sum',\n",
        "        'p90': 'mean'\n",
        "    }).round(2).reset_index()\n",
        "    route_summary.columns = ['Origin', 'Dest', 'Total Obs', 'Avg P90']\n",
        "    display(route_summary)\n",
        "else:\n",
        "    print(\"No percentiles data to save\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
